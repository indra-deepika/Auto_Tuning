{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metric(file_path = './db_bench_output.txt'):\n",
    "    metrics = {}\n",
    "    micros_op_pattern = re.compile(r\"(\\d+\\.\\d+) micros/op (\\d+) ops/sec\")\n",
    "    write_read_rate_pattern = re.compile(r\"Write rate: (\\d+) bytes/second\\nRead rate: (\\d+) ops/second\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "        \n",
    "        micros_op_match = micros_op_pattern.search(file_content)\n",
    "        if micros_op_match:\n",
    "            metrics['micros_per_op'] = float(micros_op_match.group(1))\n",
    "            metrics['ops_per_sec'] = int(micros_op_match.group(2))\n",
    "            \n",
    "\n",
    "        write_read_rate_match = write_read_rate_pattern.search(file_content)\n",
    "        if write_read_rate_match:\n",
    "            metrics['write_rate'] = int(write_read_rate_match.group(1))\n",
    "            metrics['read_rate'] = int(write_read_rate_match.group(2))\n",
    "\n",
    "    return   metrics['ops_per_sec'] , metrics['micros_per_op']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# Now you can import the module\n",
    "import rocksdb_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_workload\n",
      "recommendations\n",
      "cmd: /mnt/c/Users/edeep/Final_Rocksdb/rocksdb/db_bench --benchmarks=fillseq --num=100000 --compression_type=none --key_size=1024 --value_size=10240 --block_size=8192\n",
      "20741 48.211\n",
      "run_workload\n",
      "recommendations\n",
      "cmd: /mnt/c/Users/edeep/Final_Rocksdb/rocksdb/db_bench --benchmarks=fillseq --num=100000 --compression_type=none --key_size=1024 --value_size=10240 --block_size=8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RocksDB:    version 8.10.0\n",
      "Date:       Wed May 29 18:11:52 2024\n",
      "CPU:        12 * Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz\n",
      "CPUCache:   12288 KB\n",
      "RocksDB:    version 8.10.0                           \n",
      "Date:       Wed May 29 18:11:58 2024\n",
      "CPU:        12 * Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz\n",
      "CPUCache:   12288 KB\n",
      "... finished 100000 ops                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12089 82.714\n",
      "run_workload\n",
      "recommendations\n",
      "cmd: /mnt/c/Users/edeep/Final_Rocksdb/rocksdb/db_bench --benchmarks=fillseq --num=100000 --compression_type=none --key_size=1024 --value_size=10240 --block_size=8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RocksDB:    version 8.10.0\n",
      "Date:       Wed May 29 18:12:08 2024\n",
      "CPU:        12 * Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz\n",
      "CPUCache:   12288 KB\n",
      "RocksDB:    version 8.10.0                           \n",
      "Date:       Wed May 29 18:12:15 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16718 59.811\n",
      "run_workload\n",
      "recommendations\n",
      "cmd: /mnt/c/Users/edeep/Final_Rocksdb/rocksdb/db_bench --benchmarks=fillseq --num=100000 --compression_type=none --key_size=1024 --value_size=10240 --block_size=8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPU:        12 * Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz\n",
      "CPUCache:   12288 KB\n",
      "RocksDB:    version 8.10.0                           \n",
      "Date:       Wed May 29 18:12:20 2024\n",
      "CPU:        12 * Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz\n",
      "CPUCache:   12288 KB\n",
      "... finished 5000 ops                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26215 38.144\n",
      "run_workload\n",
      "recommendations\n",
      "cmd: /mnt/c/Users/edeep/Final_Rocksdb/rocksdb/db_bench --benchmarks=fillseq --num=100000 --compression_type=none --key_size=1024 --value_size=10240 --block_size=8192\n",
      "22007 45.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... finished 100000 ops                              \r"
     ]
    }
   ],
   "source": [
    "# Block size values\n",
    "block_size_val = [4*1024, 8*1024, 16*1024, 32*1024, 64*1024, 128*1024]\n",
    "\n",
    "# Define the CSV file to store results\n",
    "csv_file = './blocksize_random_fillseq.csv'\n",
    "\n",
    "\n",
    "# Check if the CSV file exists and write the header if it doesn't\n",
    "if not os.path.isfile(csv_file):\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Block Size', 'ops_per_sec', 'micros_per_op'])\n",
    "\n",
    "# Loop over the range of write buffer sizes\n",
    "for i in range(200):\n",
    "    # Select a random block size\n",
    "    block_size = random.choice(block_size_val)\n",
    "\n",
    "    wltype = \"fillseq\"\n",
    "    num_operations = 100000\n",
    "    db_path = \"\"  # Ensure this is correctly set or managed in your actual use case\n",
    "\n",
    "    for j in range(5):\n",
    "        # Temporary record with the current buffer size\n",
    "        rec_temp = {\"block_size\": str(block_size)}\n",
    "        other_params = {}\n",
    "\n",
    "        # Load the workload on the rocksdb_module\n",
    "        rocksdb_module.run_workload(wltype, num_operations, db_path, rec_temp, other_params)\n",
    "\n",
    "        # Read the operations and microseconds from the metric function\n",
    "        ops, micro = read_metric()\n",
    "        print(ops, micro)\n",
    "\n",
    "        # Open the CSV file in append mode and write the results\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([block_size, ops, micro])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
